# MindNote 情绪陪伴 AI - 技术架构文档 v2.0

> **混合架构版本**
> 更新日期: 2026年1月12日
> 硬件平台: 树莓派5 4GB

---

## 目录

1. [架构设计理念](#1-架构设计理念)
2. [系统架构总览](#2-系统架构总览)
3. [语音交互层](#3-layer-1-语音交互层)
4. [对话引擎层](#4-layer-2-对话引擎层)
5. [数据服务层](#5-layer-3-数据服务层)
6. [设备控制层](#6-layer-4-设备控制层)
7. [开放接口层](#7-layer-5-开放接口层可选未来)
8. [硬件配置](#8-硬件配置)
9. [本地模型配置](#9-本地模型配置)
10. [云端服务配置](#10-云端服务配置)
11. [延迟与性能](#11-延迟与性能)
12. [开发路线图](#12-开发路线图)
13. [成本分析](#13-成本分析)
14. [总结](#14-总结)

---

## 1. 架构设计理念

### 1.1 核心原则

```
本地优先 + 云端增强 = 最佳体验

┌─────────────────────────────────────────────────────────────┐
│                                                             │
│   本地处理                    云端处理                       │
│   ├── ASR (离线)             ├── LLM (深度对话)             │
│   ├── TTS (离线)             ├── 复杂分析                   │
│   ├── 意图分类               └── 长程洞察                   │
│   ├── 设备控制                                            │
│   └── 简单对话                                            │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

### 1.2 设计目标

| 目标 | 优先级 | 说明 |
|------|--------|------|
| 体验优先 | P0 | 延迟<3秒，响应自然 |
| 成本可控 | P1 | 月成本<¥10 |
| 离线可用 | P2 | 基础功能离线可用 |
| 隐私保护 | P3 | 数据优先本地处理 |
| 技术创新 | P4 | 探索边缘AI部署 |

### 1.3 架构演进

| 版本 | 架构 | 特点 |
|------|------|------|
| v1.0 | MCP驱动 | 被动响应，依赖外部调用 |
| v2.0 | 语音驱动 | 主动交互，独立运行 |
| v2.0 | 混合架构 | 本地+云端，平衡体验与成本 |

---

## 2. 系统架构总览

### 2.1 整体架构图

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                            MindNote 系统架构 v2.0                            │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  ┌──────────────────────────────────────────────────────────────────────┐  │
│  │                        Layer 1: 语音交互层                             │  │
│  │  ┌─────────┐  ┌─────────┐  ┌─────────┐  ┌─────────┐  ┌─────────┐    │  │
│  │  │ 唤醒词  │→│  VAD   │→│  ASR   │  │  TTS   │  │ 扬声器  │    │  │
│  │  │检测    │  │语音检测 │  │本地优先 │  │本地优先 │  │ 播放   │    │  │
│  │  │(本地)  │  │(本地)  │  │Sherpa  │  │Piper   │  │        │    │  │
│  │  └─────────┘  └─────────┘  └─────────┘  └─────────┘  └─────────┘    │  │
│  └──────────────────────────────────────────────────────────────────────┘  │
│                                      ↓                                      │
│  ┌──────────────────────────────────────────────────────────────────────┐  │
│  │                        Layer 2: 对话引擎层                             │  │
│  │                                                                       │  │
│  │    ┌─────────────────────────────────────────────────────────────┐    │  │
│  │    │                   本地意图路由器                             │    │  │
│  │    └─────────────────────────────────────────────────────────────┘    │  │
│  │         │                    │                    │                    │  │
│  │         ▼                    ▼                    ▼                    │  │
│  │  ┌──────────────┐   ┌──────────────┐   ┌──────────────┐             │  │
│  │  │  本地处理    │   │  本地处理    │   │  云端处理    │             │  │
│  │  │ 意图分类     │   │  设备控制    │   │  Claude API  │             │  │
│  │  │ 简单查询     │   │  快速回复    │   │  深度对话    │             │  │
│  │  │ (TFLite)    │   │  (本地)      │   │              │             │  │
│  │  └──────────────┘   └──────────────┘   └──────────────┘             │  │
│  │                                                                       │  │
│  │  ┌───────────────────────────────────────────────────────────────┐   │  │
│  │  │                    TinyLlama (可选本地LLM)                      │   │  │
│  │  │                    离线备用 / 简单对话降级                      │   │  │
│  │  └───────────────────────────────────────────────────────────────┘   │  │
│  └──────────────────────────────────────────────────────────────────────┘  │
│                                      ↓                                      │
│  ┌──────────────────────────────────────────────────────────────────────┐  │
│  │                        Layer 3: 数据服务层                            │  │
│  │                                                                       │  │
│  │  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐  ┌────────────┐  │  │
│  │  │ 对话记录    │  │ 情绪分析    │  │ 环境数据    │  │ 洞察生成   │  │  │
│  │  │ 服务       │  │ 服务       │  │ 服务       │  │ 服务      │  │  │
│  │  │ SQLite     │  │             │  │             │  │ Claude    │  │  │
│  │  └─────────────┘  └─────────────┘  └─────────────┘  └────────────┘  │  │
│  └──────────────────────────────────────────────────────────────────────┘  │
│                                      ↓                                      │
│  ┌──────────────────────────────────────────────────────────────────────┐  │
│  │                        Layer 4: 设备控制层                            │  │
│  │  ┌────────┐  ┌────────┐  ┌────────┐  ┌────────┐  ┌────────┐        │  │
│  │  │ 音量   │  │ 灯光   │  │ 屏幕   │  │ 传感器 │  │ 按键   │        │  │
│  │  │ 控制   │  │ 控制   │  │ 控制   │  │ 读取   │  │ 检测   │        │  │
│  │  └────────┘  └────────┘  └────────┘  └────────┘  └────────┘        │  │
│  └──────────────────────────────────────────────────────────────────────┘  │
│                                      ↓                                      │
│  ┌──────────────────────────────────────────────────────────────────────┐  │
│  │                   Layer 5: 开放接口层 (可选/未来)                      │  │
│  │  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐                   │  │
│  │  │ REST API   │  │ MCP Server │  │ App 接口    │                   │  │
│  │  │ (局域网)   │  │ (AI助手)   │  │ (移动端)   │                   │  │
│  │  └─────────────┘  └─────────────┘  └─────────────┘                   │  │
│  │                                                                       │  │
│  └───────────────────────────────────────────────────────────────────────┘  │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 2.2 数据流向

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                              数据流向图                                      │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  用户说话                                                                    │
│      │                                                                        │
│      ▼                                                                        │
│  ┌─────────┐                                                                 │
│  │ 唤醒词  │───→ 唤醒成功 ──→ 灯光亮起                                      │
│  │ 检测    │                                                                 │
│  └─────────┘                                                                 │
│      │                                                                        │
│      ▼                                                                        │
│  ┌─────────┐     ┌─────────┐                                                │
│  │  VAD    │────→│  录音   │                                                │
│  │ 语音检测│     │ 开始    │                                                │
│  └─────────┘     └─────────┘                                                │
│      │               │                                                       │
│      │               ▼                                                       │
│      │        ┌────────────┐                                                 │
│      │        │  ASR本地   │                                                 │
│      │        │ Sherpa-onnx│                                                 │
│      │        └────────────┘                                                 │
│      │              │                                                        │
│      │              ▼                                                        │
│      │        ┌────────────┐                                                 │
│      │        │  文本      │                                                 │
│      │        └────────────┘                                                 │
│      │              │                                                        │
│      │              ▼                                                        │
│      │        ┌────────────┐     ┌───────────────────┐                      │
│      │        │  意图分类  │────→│  意图路由决策     │                      │
│      │        │  (本地)    │     │                   │                      │
│      │        └────────────┘     └───────────────────┘                      │
│      │              │                    │       │       │                   │
│      │              │                    ▼       ▼       ▼                   │
│      │              │           ┌──────────┐ ┌──────────┐ ┌──────────┐      │
│      │              │           │ 本地处理 │ │ TinyLlama│ │ Claude   │      │
│      │              │           │ 快速回复 │ │ 本地LLM  │ │ 云端LLM  │      │
│      │              │           └──────────┘ └──────────┘ └──────────┘      │
│      │              │                    │       │       │                   │
│      │              │                    ▼       │       ▼                   │
│      │              │           ┌──────────┐       │  ┌──────────┐          │
│      │              │           │  本地    │       │  │  云端    │          │
│      │              │           │  TTS     │       │  │  TTS     │          │
│      │              │           │ Piper    │       │  │ 备用     │          │
│      │              │           └──────────┘       │  └──────────┘          │
│      │              │                 │            │         │               │
│      │              │                 ▼            │         ▼               │
│      │              │           ┌──────────┐        │   ┌──────────┐        │
│      │              │           │  播放    │        │   │  播放    │        │
│      │              │           │ 回复     │        │   │ 回复     │        │
│      │              │           └──────────┘        │   └──────────┘        │
│      │              │                 │            │         │               │
│      │              │                 │            │         │               │
│      │              │                 ▼            │         ▼               │
│      │              │           ┌──────────────────────────────┐             │
│      │              │           │        数据记录              │             │
│      │              │           │  对话、情绪、环境存储        │             │
│      │              │           └──────────────────────────────┘             │
│      │              │                          │                               │
│      │              │                          ▼                               │
│      │              │                   ┌─────────────┐                       │
│      │              │                   │  数据库     │                       │
│      │              │                   │  SQLite     │                       │
│      │              │                   └─────────────┘                       │
│      │              │                                                         │
│      └──────────────┴─────────────────────────────────────────────────────────┘
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

## 3. Layer 1: 语音交互层

### 3.1 语音处理流程

```
用户说话
    │
    ▼
┌─────────────────┐
│  唤醒词检测      │ ← Porcupine，本地运行，持续监听
│  "小心"         │   误唤醒率 <1次/天，延迟 <100ms
└─────────────────┘
    │ 唤醒成功，灯光亮起
    ▼
┌─────────────────┐
│  VAD 语音检测    │ ← WebRTC VAD，本地运行
│                 │   检测说话开始/结束，支持打断
└─────────────────┘
    │ 录音完成
    ▼
┌─────────────────┐
│  ASR 语音识别    │ ← Sherpa-onnx (主) / 讯飞云端 (备)
│  本地优先       │   准确率 >95%，离线可用
└─────────────────┘
    │ 文本结果
    ▼
  对话引擎层
```

### 3.2 语音模块技术选型

| 模块 | 主方案 | 备选方案 | 说明 |
|------|--------|---------|------|
| 唤醒词 | Porcupine | 物理按钮 | 本地运行，低功耗 |
| VAD | WebRTC VAD | Silero VAD | 本地运行，<50ms |
| ASR | **Sherpa-onnx** | 讯飞云端 | 本地Whisper优化版 |
| TTS | **Piper** | 讯飞云端 | 本地离线TTS |
| 音频IO | ALSA/PulseAudio | - | 树莓派原生支持 |

### 3.3 唤醒词检测

```python
# wakeword.py - 唤醒词检测模块
import pvporcupine

class WakewordDetector:
    def __init__(self, wakeword="小心"):
        self.porcupine = pvporcupine.create(
            keywords=[wakeword],
            access_key="YOUR_ACCESS_KEY"
        )
        self.is_listening = False

    async def wait_for_wakeword(self):
        """等待唤醒词"""
        while True:
            audio_frame = await self.capture_audio()
            result = self.porcupine.process(audio_frame)
            if result >= 0:
                return True

    def get_audio_chunk(self):
        """获取音频数据用于检测"""
        pass
```

### 3.4 VAD 语音活动检测

```python
# vad.py - 语音活动检测模块
import webrtcvad

class VAD:
    def __init__(self):
        self.vad = webrtcvad.create(2)  # 激进程度 0-3
        self.sample_rate = 16000

    async def record_until_silence(self, timeout=5):
        """录制直到检测到静音"""
        # 实现录制逻辑，超时自动停止
        pass

    def is_speech(self, audio_frame):
        """判断是否为语音"""
        return self.vad.is_speech(audio_frame, self.sample_rate)
```

### 3.5 ASR 模块

#### 3.5.1 本地 ASR - Sherpa-onnx

```python
# asr/local_asr.py - 本地语音识别
import sherpa_onnx

class LocalASR:
    def __init__(self):
        self.offline_recognizer = sherpa_onnx.OfflineRecognizer.from_files(
            encoder="models/sherpa-onnx-conformer-zh-small/encoder.onnx",
            decoder="models/sherpa-onnx-conformer-zh-small/decoder.onnx",
            joiner="models/sherpa-onnx-conformer-zh-small/joiner.onnx",
            tokens="models/sherpa-onnx-conformer-zh-small/tokens.txt",
        )

    async def recognize(self, audio_data):
        """识别音频为文本"""
        stream = self.offline_recognizer.create_stream()
        stream.accept_waveform(audio_data, sample_rate=16000)
        self.offline_recognizer.decode_stream(stream)
        return stream.result.text
```

**配置参数**:

| 参数 | 值 |
|------|-----|
| 模型 | sherpa-onnx-conformer-zh-small-2024-07-17 |
| 模型大小 | ~40MB |
| 内存占用 | ~400MB |
| RTF | 0.2-0.3 |
| 准确率 | ~95% |
| 支持语言 | 中文/英文 |

#### 3.5.2 云端 ASR 备用

```python
# asr/cloud_asr.py - 云端语音识别备用方案
import requests

class CloudASR:
    def __init__(self, api_key):
        self.api_key = api_key
        self.url = "https://iat-api.xfyun.cn/v2/iat"

    async def recognize(self, audio_data):
        """调用讯飞云端ASR"""
        # 备用方案，仅在本地ASR失败时调用
        pass
```

### 3.6 TTS 模块

#### 3.6.1 本地 TTS - Piper

```python
# tts/local_tts.py - 本地语音合成
import piper

class LocalTTS:
    def __init__(self):
        self.synthesizer = piper.PiperVoice.load(
            "models/piper/zh_CN_Huayan-medium.onnx"
        )

    async def speak(self, text):
        """生成并播放语音"""
        audio = self.synthesizer.synthesize(text)
        await self.play_audio(audio)

    def speak_sync(self, text):
        """同步生成音频（用于调试）"""
        audio = self.synthesizer.synthesize(text)
        return audio
```

**配置参数**:

| 参数 | 值 |
|------|-----|
| 模型 | zh_CN_Huayan-medium.onnx |
| 模型大小 | ~50MB |
| 内存占用 | ~200MB |
| 延迟 | <150ms |
| 音质(MOS) | 3.5-4.0 |
| 支持语言 | 中文 |

#### 3.6.2 云端 TTS 备用

```python
# tts/cloud_tts.py - 云端语音合成备用方案
class CloudTTS:
    async def synthesize(self, text):
        """调用讯飞云端TTS"""
        pass
```

### 3.7 音频IO配置

```python
# audio/config.py - 音频配置
AUDIO_CONFIG = {
    "sample_rate": 16000,
    "channels": 1,
    "chunk_size": 1024,
    "record_timeout": 5.0,
    "phrase_timeout": 1.5,

    "input_device": None,  # 默认麦克风
    "output_device": None,  # 默认扬声器

    # USB麦克风配置
    "usb_mic": {
        "device_index": 0,
        "channels": 1,
        "sample_rate": 16000
    },

    # 蓝牙扬声器配置
    "bluetooth": {
        "device_name": "MindNote-Speaker",
        "profile": "a2dp"
    }
}
```

---

## 4. Layer 2: 对话引擎层

### 4.1 对话路由设计

```
用户输入文本
      │
      ▼
┌──────────────────┐
│  本地意图分类     │ ← TFLite 模型，<50ms
│  (20+ 意图分类)   │
└──────────────────┘
      │
      ├─── 设备控制意图 ───→ 本地处理 → 本地 TTS
      │    "音量大一点"        执行控制     "好的"
      │    响应时间: <500ms
      │
      ├─── 简单查询意图 ───→ 本地处理 → 本地 TTS
      │    "现在几点"          查询数据     "下午3点"
      │    响应时间: <500ms
      │
      ├─── 简单对话意图 ───→ TinyLlama → 本地 TTS
      │    "你好"              本地推理     "你好呀"
      │    响应时间: <2s
      │
      └─── 复杂意图 ───────→ Claude API → 云端 TTS/本地 TTS
           "我今天好累"        深度对话     温暖回复
           响应时间: 1-3s
```

### 4.2 意图分类器

```python
# intent/classifier.py - 本地意图分类
import tensorflow as tf
import numpy as np

class IntentClassifier:
    def __init__(self):
        self.model = tf.lite.Interpreter(model_path="models/intent_classifier.tflite")
        self.model.allocate_tensors()
        self.labels = [
            "volume_up", "volume_down", "light_on", "light_off",
            "query_time", "query_date", "query_weather", "query_environment",
            "emotion_talk", "casual_chat", "ask_advice", "share_story",
            "stop", "repeat", "cancel", "greeting", "goodbye"
        ]

    def classify(self, text):
        """分类用户意图"""
        # 预处理文本
        features = self.preprocess(text)
        # 推理
        self.model.set_tensor(input_details[0]['index'], features)
        self.model.invoke()
        predictions = self.model.get_tensor(output_details[0]['index'])
        # 返回最高概率的意图
        intent_id = np.argmax(predictions)
        return self.labels[intent_id]
```

### 4.3 意图定义

```python
# dialog/intents.py - 意图定义

# 本地快速处理意图（约15个）
LOCAL_INTENTS = {
    # 设备控制
    "volume_up": ["大声点", "音量调高", "听不清", "大点声"],
    "volume_down": ["小声点", "音量调低", "太吵了", "小点声"],
    "volume_set": ["音量调到50", "音量80", "音量最大"],
    "light_on": ["开灯", "打开灯光", "灯打开"],
    "light_off": ["关灯", "把灯关了", "灯关掉"],
    "light_color": ["蓝色灯光", "暖光", "换个颜色", "灯光变色"],

    # 简单查询
    "query_time": ["几点了", "现在时间", "几点", "现在几点"],
    "query_date": ["今天几号", "星期几", "今天星期几", "日期"],
    "query_weather": ["天气怎么样", "会下雨吗", "今天天气", "天气"],
    "query_environment": ["房间温度", "湿度多少", "现在温度", "环境数据"],

    # 系统控制
    "stop": ["停", "闭嘴", "别说了", "停止"],
    "repeat": ["再说一遍", "没听清", "重复"],
    "cancel": ["取消", "算了", "不用了"],
}

# 简单对话意图 - 本地LLM处理
LOCAL_LLM_INTENTS = {
    "greeting": ["你好", "hi", "hello", "在吗", "有人吗"],
    "goodbye": ["再见", "拜拜", "晚安", "再见吧"],
    "thanks": ["谢谢", "感谢", "太感谢了"],
    "simple_chat": ["你好呀", "最近怎么样", "在干嘛", "无聊"],
}

# 云端LLM处理意图 - 国产大模型
CLOUD_LLM_INTENTS = {
    "emotion_talk": ["我好累", "心情不好", "很开心", "有点焦虑",
                     "今天发生了一件事", "想聊聊", "心里烦"],
    "casual_chat": ["聊聊天", "无聊", "陪我说话", "说说话"],
    "ask_advice": ["怎么办", "给我建议", "你觉得呢", "建议"],
    "share_story": ["告诉你一件事", "今天发生了", "跟你说"],
    "query_emotion": ["我最近情绪怎么样", "上周聊了什么", "我开心吗"],
    "deep_talk": ["生命的意义", "你觉得AI有意识吗", "哲学问题"],
}
```

### 4.4 本地意图处理

```python
# dialog/local_handler.py - 本地意图处理器
from device import DeviceController
from services import EnvironmentService

class LocalHandler:
    def __init__(self):
        self.device = DeviceController()
        self.env_service = EnvironmentService()

    def handle(self, intent, text):
        """处理本地意图"""
        handlers = {
            # 设备控制
            "volume_up": self._handle_volume_up,
            "volume_down": self._handle_volume_down,
            "light_on": self._handle_light_on,
            "light_off": self._handle_light_off,

            # 简单查询
            "query_time": self._handle_query_time,
            "query_date": self._handle_query_date,
            "query_weather": self._handle_query_weather,
            "query_environment": self._handle_query_environment,

            # 系统控制
            "stop": self._handle_stop,
            "repeat": self._handle_repeat,
            "cancel": self._handle_cancel,
        }

        handler = handlers.get(intent)
        if handler:
            return handler(text)
        return "我没听清，请再说一次"

    def _handle_volume_up(self, text):
        self.device.volume_up()
        return "好的，音量已经调大"

    def _handle_volume_down(self, text):
        self.device.volume_down()
        return "好的，音量已经调小"

    def _handle_query_time(self, text):
        from datetime import datetime
        now = datetime.now()
        return f"现在是{now.hpoint}:{now.minute:02d}"

    def _handle_query_environment(self, text):
        env = self.env_service.get_current()
        return f"当前室内温度{env.temperature}度，湿度{env.humidity}%"
```

### 4.5 本地LLM - TinyLlama

```python
# llm/local_llm.py - 本地LLM处理器
import llama_cpp

class LocalLLM:
    def __init__(self):
        self.llm = llama_cpp.Llama(
            model_path="models/TinyLlama-1.1B-Chat.Q4_0.gguf",
            n_ctx=2048,
            n_threads=4,
            temperature=0.7,
            top_p=0.9,
            stop=["用户:", "Human:", "###"]
        )

    def chat(self, message, history=None):
        """本地推理对话"""
        prompt = self._build_prompt(message, history)
        response = self.llm(prompt, max_tokens=100)
        return response["choices"][0]["text"]

    def _build_prompt(self, message, history):
        """构建prompt"""
        if history:
            prompt = f"### 对话历史:\n{history}\n### 当前:\n用户: {message}\n助手: "
        else:
            prompt = f"用户: {message}\n助手: "
        return prompt
```

### 4.6 云端LLM - 国产大模型推荐

**推荐选择：豆包 (Doubao) 或 智谱AI (GLM)**

#### 4.6.1 价格对比

| 服务商 | 模型 | 输入价格 | 输出价格 | 月成本(450K tokens) |
|--------|------|---------|---------|-------------------|
| **豆包** | Doubao-Seed-1.6-lite | ¥0.3/百万 | ¥0.5/百万 | **¥0.27** ✅ 推荐 |
| **豆包** | Doubao-Seed-1.6 | ¥0.5/百万 | ¥1.0/百万 | ¥0.50 |
| **智谱AI** | GLM-4-Air | ¥0.6/百万 | ¥0.6/百万 | ¥0.27 ✅ 推荐 |
| **MiniMax** | abab-6.5t-chat | ¥1.0/百万 | ¥1.0/百万 | ¥0.45 |
| ~~Claude~~ | ~~Claude 3.5~~ | ~~$3/百万~~ | ~~$15/百万~~ | ~~约¥45~~ ❌ |

> 注：月成本按70%输入+30%输出估算

#### 4.6.2 推荐方案

**首选：豆包 Doubao-Seed-1.6-lite**
- 价格最低：¥0.27/月
- 响应速度快
- 国内访问稳定

**备选：智谱AI GLM-4-Air**
- 价格相同：¥0.27/月
- 能力稍强
- 企业级服务

#### 4.6.3 代码示例（豆包）

```python
# llm/cloud_llm.py - 豆包API客户端
import aiohttp

class CloudLLM:
    def __init__(self, api_key):
        self.api_key = api_key
        self.model = "Doubao-Seed-1.6-lite"  # 推荐
        self.url = "https://ark.cn-beijing.volces.com/api/v3/chat/completions"

    async def chat(self, message, history=None, context=None):
        """调用豆包API"""
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }

        messages = [{"role": "user", "content": message}]
        if history:
            messages = history + messages

        payload = {
            "model": self.model,
            "messages": messages,
            "max_tokens": 1024,
            "temperature": 0.7
        }

        async with aiohttp.ClientSession() as session:
            async with session.post(self.url, headers=headers, json=payload) as resp:
                result = await resp.json()
                return result["choices"][0]["message"]["content"]

    def _build_system_prompt(self, context):
        """构建系统prompt"""
        return f"""你是小心，一个温暖、善解人意的情绪陪伴伙伴。

当前上下文:
- 用户名: {context.get('user_name', '朋友')}
- 当前时间: {context.get('current_time', '')}
- 环境: 室内{context.get('temperature', '')}°C，{context.get('weather', '')}
- 最近情绪: {context.get('recent_mood', '')}

## 你的性格
- 温暖、耐心、善于倾听
- 像一个贴心的朋友，不是冷冰冰的助手
- 偶尔俏皮，但不轻浮
- 真诚关心用户，不敷衍

## 对话原则
- 先倾听和共情，再给建议
- 不说教，不评判
- 用简短、自然的语言回复
- 记住用户说过的事情

## 边界
- 不提供医疗/心理诊断建议
- 严重情况建议寻求专业帮助
"""
```

#### 4.6.4 API申请

**豆包API申请**:
1. 访问 https://www.volcengine.com/product/doubao
2. 注册账号，实名认证
3. 创建API Key
4. 新用户赠送50万tokens

**智谱AI API申请**:
1. 访问 https://www.bigmodel.cn
2. 注册账号
3. 创建API Key
4. 新用户赠送2000万tokens

#### 4.6.5 成本控制建议

```python
# 成本优化策略
COST_OPTIMIZATION = {
    "减少调用": {
        "意图分类前置": "简单问题本地处理，不调用云端",
        "缓存常见回复": "重复问题直接返回缓存",
        "短上下文": "只传递最近5轮对话历史"
    },
    "降低token消耗": {
        "精简prompt": "系统提示控制在500字以内",
        "限制回复长度": "max_tokens=512而非1024",
        "压缩历史": "摘要式存储对话历史"
    },
    "监控告警": {
        "月度预算": "设置¥5/月预算上限",
        "使用量监控": "每日检查API调用量"
    }
}
```

### 4.7 对话路由器

```python
# dialog/router.py - 对话路由器
from intent import LOCAL_INTENTS, LOCAL_LLM_INTENTS, CLOUD_LLM_INTENTS

class DialogRouter:
    def __init__(self, classifier, local_handler, local_llm, cloud_llm):
        self.classifier = classifier
        self.local_handler = local_handler
        self.local_llm = local_llm
        self.cloud_llm = cloud_llm

    async def route(self, text, history=None, context=None):
        """路由对话到合适的处理器"""
        # 1. 意图分类
        intent = self.classifier.classify(text)

        # 2. 路由决策
        if intent in LOCAL_INTENTS:
            # 设备控制或简单查询 - 本地处理
            response = self.local_handler.handle(intent, text)
            source = "local_handler"

        elif intent in LOCAL_LLM_INTENTS:
            # 简单对话 - 本地LLM
            response = self.local_llm.chat(text, history)
            source = "local_llm"

        elif intent in CLOUD_LLM_INTENTS:
            # 复杂对话 - 云端LLM
            response = await self.cloud_llm.chat(text, history, context)
            source = "cloud_llm"

        else:
            # 默认走云端
            response = await self.cloud_llm.chat(text, history, context)
            source = "cloud_llm_default"

        return {
            "response": response,
            "intent": intent,
            "source": source
        }
```

---

## 5. Layer 3: 数据服务层

### 5.1 服务模块设计

```
┌─────────────────────────────────────────────────────────────┐
│                      数据服务层                              │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  ┌─────────────────┐  ┌─────────────────┐                  │
│  │ ConversationDB  │  │ EmotionService  │                  │
│  │ 对话记录服务     │  │ 情绪分析服务     │                  │
│  │                 │  │                 │                  │
│  │ • 保存对话历史   │  │ • 从对话提取情绪 │                  │
│  │ • 查询历史对话   │  │ • 记录情绪数据   │                  │
│  │ • 生成对话摘要   │  │ • 生成情绪报告   │                  │
│  │                 │  │ • Claude分析    │                  │
│  └─────────────────┘  └─────────────────┘                  │
│                                                             │
│  ┌─────────────────┐  ┌─────────────────┐                  │
│  │ EnvironmentSvc  │  │ InsightService  │                  │
│  │ 环境数据服务     │  │ 洞察生成服务     │                  │
│  │                 │  │                 │                  │
│  │ • 读取传感器    │  │ • 分析情绪趋势   │                  │
│  │ • 获取天气数据  │  │ • 环境关联分析   │                  │
│  │ • 记录环境历史  │  │ • 生成改善建议   │                  │
│  └─────────────────┘  └─────────────────┘                  │
│                                                             │
│  ┌─────────────────────────────────────────────────────┐   │
│  │                   SQLite 数据库                      │   │
│  │  conversations | emotions | environment | insights  │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

### 5.2 数据模型

```sql
-- 数据库: data/mindnote.db

-- 对话记录
CREATE TABLE conversations (
    id INTEGER PRIMARY KEY,
    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
    user_input TEXT,
    ai_response TEXT,
    intent TEXT,
    emotion_detected TEXT,
    source TEXT,  -- 'local_handler' | 'local_llm' | 'cloud_llm'
    duration_seconds INTEGER
);

-- 情绪记录
CREATE TABLE emotions (
    id INTEGER PRIMARY KEY,
    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
    mood_score INTEGER,  -- 1-10
    mood_tags TEXT,      -- JSON array
    mood_summary TEXT,   -- AI分析的情绪摘要
    source TEXT,         -- 'conversation' | 'manual' | 'insight'
    environment_id INTEGER,
    conversation_id INTEGER
);

-- 环境数据
CREATE TABLE environment (
    id INTEGER PRIMARY KEY,
    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
    temperature REAL,
    humidity REAL,
    light_level INTEGER,
    indoor REAL,  -- 室内舒适度评分
    weather TEXT,  -- 室外天气
    weather_temp REAL  -- 室外温度
);

-- 洞察记录
CREATE TABLE insights (
    id INTEGER PRIMARY KEY,
    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
    insight_type TEXT,  -- 'daily' | 'weekly' | 'monthly' | 'trend'
    title TEXT,
    content TEXT,  -- JSON格式的洞察内容
    recommendation TEXT  -- 改善建议
);

-- 用户画像（简化版）
CREATE TABLE user_profile (
    id INTEGER PRIMARY KEY,
    key TEXT UNIQUE,
    value TEXT,
    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
);
```

### 5.3 对话记录服务

```python
# services/conversation.py
import sqlite3
from datetime import datetime

class ConversationDB:
    def __init__(self, db_path="data/mindnote.db"):
        self.db_path = db_path
        self._init_db()

    def _init_db(self):
        """初始化数据库"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("""
                CREATE TABLE IF NOT EXISTS conversations (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                    user_input TEXT,
                    ai_response TEXT,
                    intent TEXT,
                    emotion_detected TEXT,
                    source TEXT,
                    duration_seconds INTEGER
                )
            """)

    def save(self, user_input, ai_response, intent, emotion_detected=None,
             source="cloud_llm", duration_seconds=None):
        """保存对话"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("""
                INSERT INTO conversations
                (user_input, ai_response, intent, emotion_detected, source, duration_seconds)
                VALUES (?, ?, ?, ?, ?, ?)
            """, (user_input, ai_response, intent, emotion_detected, source, duration_seconds))

    def get_recent(self, limit=20):
        """获取最近的对话记录"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute("""
                SELECT * FROM conversations
                ORDER BY timestamp DESC
                LIMIT ?
            """, (limit,))
            return cursor.fetchall()

    def get_history_for_llm(self, limit=10):
        """获取适合LLM上下文的对话历史"""
        conversations = self.get_recent(limit)
        history = []
        for conv in reversed(conversations):
            history.append(f"用户: {conv[2]}")
            history.append(f"助手: {conv[3]}")
        return "\n".join(history)
```

### 5.4 情绪分析服务

```python
# services/emotion.py
import sqlite3
import json
from datetime import datetime, timedelta

class EmotionService:
    def __init__(self, db_path="data/mindnote.db"):
        self.db_path = db_path

    def analyze_from_text(self, text):
        """从对话文本分析情绪"""
        # 使用关键词匹配和简单规则
        # 实际可接入情感分析模型
        emotions = {
            "positive": ["开心", "高兴", "愉快", "兴奋", "激动", "满意"],
            "negative": ["难过", "悲伤", "沮丧", "焦虑", "烦躁", "生气"],
            "neutral": ["一般", "还行", "普通"]
        }

        for emotion, keywords in emotions.items():
            for keyword in keywords:
                if keyword in text:
                    return emotion
        return "unknown"

    def record(self, mood_score, mood_tags, mood_summary, source="conversation"):
        """记录情绪"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("""
                INSERT INTO emotions (mood_score, mood_tags, mood_summary, source)
                VALUES (?, ?, ?, ?)
            """, (mood_score, json.dumps(mood_tags), mood_summary, source))

    def get_recent_mood(self, days=7):
        """获取最近N天的情绪趋势"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute("""
                SELECT timestamp, mood_score, mood_tags
                FROM emotions
                WHERE timestamp > datetime('now', ?)
                ORDER BY timestamp ASC
            """, (f"-{days} days",))
            return cursor.fetchall()

    def get_weekly_summary(self):
        """生成周度情绪总结"""
        # 调用Claude API生成总结
        pass
```

### 5.5 环境数据服务

```python
# services/environment.py
import sqlite3
import requests
from datetime import datetime

class EnvironmentService:
    def __init__(self, db_path="data/mindnote.db"):
        self.db_path = db_path
        self.sensor = None  # SHT30传感器实例
        self.weather_api_key = "YOUR_QWEATHER_API_KEY"
        self.location = "深圳"  # 可配置

    def get_current(self):
        """获取当前环境数据"""
        # 1. 读取传感器
        if self.sensor:
            temp, hum = self.sensor.read()
        else:
            # 模拟数据
            temp, hum = 25.0, 60.0

        # 2. 获取天气
        weather = self.get_weather()

        # 3. 计算室内舒适度
        indoor_score = self.calculate_comfort(temp, hum)

        # 4. 保存
        self._save(temp, hum, weather, indoor_score)

        return {
            "temperature": temp,
            "humidity": hum,
            "weather": weather.get("text", "未知"),
            "weather_temp": weather.get("temp", None),
            "indoor_score": indoor_score,
            "timestamp": datetime.now().isoformat()
        }

    def get_weather(self):
        """获取室外天气"""
        try:
            # 和风天气API
            url = f"https://api.qweather.com/v7/weather/now?location=101280600&key={self.weather_api_key}"
            response = requests.get(url, timeout=5)
            data = response.json()
            if data.get("code") == "200":
                return {
                    "text": data.get("now", {}).get("text", ""),
                    "temp": data.get("now", {}).get("temp", "")
                }
        except:
            pass
        return {"text": "未知", "temp": None}

    def calculate_comfort(self, temp, hum):
        """计算舒适度评分 (0-100)"""
        # 简化的舒适度算法
        # 温度22-26°C，湿度40-60%为最舒适
        temp_score = 100 - abs(temp - 24) * 5
        hum_score = 100 - abs(hum - 50) * 2
        return max(0, min(100, (temp_score + hum_score) // 2))

    def _save(self, temp, hum, weather, indoor_score):
        """保存环境数据"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("""
                INSERT INTO environment (temperature, humidity, weather, weather_temp, indoor)
                VALUES (?, ?, ?, ?, ?)
            """, (temp, hum, weather.get("text"), weather.get("temp"), indoor_score))
```

### 5.6 洞察生成服务

```python
# services/insight.py
from llm.cloud_llm import CloudLLM

class InsightService:
    def __init__(self):
        self.llm = CloudLLM()

    async def generate_weekly_insight(self, emotion_data, env_data):
        """生成周度洞察"""
        prompt = f"""
请分析以下数据，生成周度情绪洞察报告：

情绪数据: {emotion_data}
环境数据: {env_data}

请生成:
1. 本周情绪概览
2. 主要情绪变化趋势
3. 环境因素影响分析
4. 改善建议

请用温暖、鼓励的语气回复。
"""
        response = await self.llm.chat(prompt, context={})
        return response

    async def generate_recommendation(self, current_mood, env_data):
        """生成即时建议"""
        prompt = f"""
用户当前情绪: {current_mood}
当前环境: {env_data}

请给出一条简短、实用的建议（不超过50字），帮助改善用户状态。
用温暖的语气。
"""
        response = await self.llm.chat(prompt, context={})
        return response
```

---

## 6. Layer 4: 设备控制层

### 6.1 设备控制器

```python
# device/controller.py - 设备控制器
import subprocess
import os

class DeviceController:
    def __init__(self):
        self.volume = 70
        self.brightness = 80
        self.light_on = True
        self.light_color = (255, 200, 150)

    # 音量控制
    def set_volume(self, value: int):
        self.volume = max(0, min(100, value))
        subprocess.run(["amixer", "sset", "Master", f"{self.volume}%"])

    def volume_up(self, delta=20):
        self.set_volume(self.volume + delta)
        return "好的，音量已经调大"

    def volume_down(self, delta=20):
        self.set_volume(self.volume - delta)
        return "好的，音量已经调小"

    # 灯光控制
    def set_light(self, on: bool, color: tuple = None):
        self.light_on = on
        if color:
            self.light_color = color
        # 控制LED
        if self.light_on:
            self._set_led_color(color or self.light_color)

    def _set_led_color(self, color):
        """设置LED颜色"""
        # 使用rpi-ws281x库控制WS2812 LED
        pass
```

### 6.2 传感器读取

```python
# device/sensors.py - 传感器读取
import smbus2
import bme280

class SHT30Sensor:
    """SHT30温湿度传感器"""

    def __init__(self, bus=1, address=0x44):
        self.bus = smbus2.SMBus(bus)
        self.address = address

    def read(self):
        """读取温湿度"""
        # 发送测量命令
        self.bus.write_i2c_block_data(self.address, 0x2C, [0x06])
        import time
        time.sleep(0.05)

        # 读取数据
        data = self.bus.read_i2c_block_data(self.address, 0, 6)

        # 解析
        temperature = -45 + (175 * (data[0] * 256 + data[1]) / 65535.0)
        humidity = 100 * (data[3] * 256 + data[4]) / 65535.0

        return round(temperature, 1), round(humidity, 1)
```

### 6.3 LED灯光效果

```python
# device/led.py - LED灯光控制
import time

class LEDController:
    """WS2812 LED控制"""

    def __init__(self, num_leds=12):
        self.num_leds = num_leds
        # 使用rpi-ws281x库
        # from rpi_ws281x import PixelStrip, Color
        # self.strip = PixelStrip(num_leds, 18)
        # self.strip.begin()

    def show_idle(self):
        """待机状态 - 柔和呼吸灯（暖白）"""
        pass

    def show_listening(self):
        """聆听状态 - 蓝色渐亮"""
        pass

    def show_thinking(self):
        """思考状态 - 蓝色流动"""
        pass

    def show_speaking(self):
        """说话状态 - 随语音律动"""
        pass

    def show_emotion(self, emotion):
        """情绪状态灯光"""
        colors = {
            "happy": (255, 200, 0),    # 暖黄
            "calm": (0, 255, 200),     # 青绿
            "sad": (100, 100, 255),    # 蓝调
            "angry": (255, 50, 50),    # 红
        }
        color = colors.get(emotion, (255, 255, 255))
        self._set_all(color)

    def _set_all(self, color):
        """设置所有LED颜色"""
        pass
```

---

## 7. Layer 5: 开放接口层 (可选/未来)

### 7.1 REST API

```python
# api/rest.py - REST API接口
from flask import Flask, jsonify

app = Flask(__name__)

@app.route("/api/status")
def get_status():
    """获取设备状态"""
    return jsonify({
        "online": True,
        "uptime": 3600,
        "conversations_today": 5
    })

@app.route("/api/emotions")
def get_emotions():
    """获取情绪记录"""
    pass

@app.route("/api/conversations")
def get_conversations():
    """获取对话历史"""
    pass

@app.route("/api/insights")
def get_insights():
    """获取洞察报告"""
    pass

@app.route("/api/device/volume", methods=["POST"])
def set_volume():
    """设置音量"""
    pass

@app.route("/api/device/light", methods=["POST"])
def set_light():
    """设置灯光"""
    pass
```

### 7.2 MCP Server

```python
# api/mcp.py - MCP Server
# MCP工具定义 - 供外部AI助手调用

mcp_tools = [
    {
        "name": "get_user_mood",
        "description": "获取用户最近的情绪状态",
        "parameters": {
            "type": "object",
            "properties": {
                "days": {"type": "integer", "default": 7}
            }
        }
    },
    {
        "name": "get_mood_history",
        "description": "获取情绪历史趋势",
        "parameters": {
            "type": "object",
            "properties": {
                "start_date": {"type": "string"},
                "end_date": {"type": "string"}
            }
        }
    },
    {
        "name": "get_environment",
        "description": "获取当前环境数据",
        "parameters": {"type": "object", "properties": {}}
    },
    {
        "name": "send_message",
        "description": "让设备对用户说一句话",
        "parameters": {
            "type": "object",
            "properties": {
                "message": {"type": "string"}
            }
        }
    }
]
```

---

## 8. 硬件配置

### 8.1 硬件清单

| 配件 | 型号/规格 | 价格 | 备注 |
|------|-----------|------|------|
| 主控 | 树莓派5 4GB | ¥0 | 用户已有 |
| 电源 | 官方PD 5V/5A | ¥100 | 必须品 |
| SD卡 | 64GB | ¥50 | 系统盘 |
| USB麦克风 | 桌面USB麦 | ¥50 | 即插即用 |
| 扬声器 | 蓝牙/3.5mm | ¥0 | 自备 |
| 传感器 | SHT30 I2C模块 | ¥15 | 温湿度 |
| 杜邦线 | 公母头 ×20 | ¥5 | 连接传感器 |
| LED灯珠 | WS2812 ×12 | ¥10 | 灯光反馈 |
| 外壳 | 亚克力/3D打印 | ¥80 | 保护+美观 |
| **总计** | - | **¥310-360** | - |

### 8.2 树莓派5规格

```
┌─────────────────────────────────────────────────────────────┐
│                    树莓派 5 规格                            │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  CPU:    Cortex-A76 4核 @ 2.4GHz                           │
│  GPU:    VideoCore VII (支持Vulkan 1.2)                     │
│  RAM:    4GB LPDDR4X                                       │
│  存储:   MicroSD卡槽                                       │
│  网络:   WiFi 5 (802.11ac) + Bluetooth 5.0                  │
│  IO:     2×USB 3.0, 2×USB 2.0, 2×HDMI, GPIO               │
│  电源:   USB-C PD 5V/5A                                    │
│  功耗:   空闲 3-5W / 满载 8-15W                            │
│  尺寸:   85×56mm                                           │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

### 8.3 连接方式

```
树莓派5 接口布局:

  ┌──────────────────────────────────────────────┐
  │  USB-C   USB3.0   USB3.0   HDMI   HDMI   GPIO │
  │  电源      A        B       micro  micro       │
  │                                              │
  │                                    ┌──────┐  │
  │                                    │Micro │  │
  │                                    │ SD   │  │
  │                                    └──────┘  │
  │                                              │
  │  ┌────────────────────────────────────────┐  │
  │  │           40-pin GPIO                  │  │
  │  │  3.3V  5V  GPIO2  GPIO3  GND  GPIO4   │  │
  │  │  ...   ...  SDA   SCL   ...   ...     │  │
  │  │                                       │  │
  │  │  SHT30连接:                           │  │
  │  │  - Pin 1 (3.3V) → VCC                │  │
  │  │  - Pin 3 (SDA) → SDA                 │  │
  │  │  - Pin 5 (SCL) → SCL                 │  │
  │  │  - Pin 6 (GND) → GND                 │  │
  │  └────────────────────────────────────────┘  │
  └──────────────────────────────────────────────┘
```

### 8.4 功耗与散热

| 状态 | 功耗 | 发热 | 散热需求 |
|------|------|------|---------|
| 空闲 | 3-5W | 温热 | 无需 |
| ASR推理 | 5-8W | 热 | 散热片 |
| LLM推理 | 8-12W | 很热 | **必须风扇** |
| 峰值 | 15W | 烫 | 主动散热 |

**推荐散热方案**:
- 铝制散热外壳: ¥30
- 5V PWM风扇: ¥15
- 导热硅脂: ¥5

---

## 9. 本地模型配置

### 9.1 ASR模型 - Sherpa-onnx

**推荐配置**:

```yaml
模型: sherpa-onnx-conformer-zh-small-2024-07-17
├── encoder.onnx (~30MB)
├── decoder.onnx (~5MB)
├── joiner.onnx (~5MB)
└── tokens.txt (~50KB)

总计: ~40MB
内存占用: ~400MB
```

**安装**:

```bash
pip install sherpa-onnx

# 下载模型
mkdir -p models/sherpa-onnx-conformer-zh-small
cd models/sherpa-onnx-conformer-zh-small
wget https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-conformer-zh-small-2024-07-17.tar.bz2
tar xvf sherpa-onnx-conformer-zh-small-2024-07-17.tar.bz2
```

### 9.2 TTS模型 - Piper

**推荐配置**:

```yaml
模型: zh_CN_Huayan-medium.onnx
├── zh_CN_Huayan-medium.onnx (~45MB)
└── zh_CN_Huayan-medium.onnx.json (~5KB)

总计: ~50MB
内存占用: ~200MB
```

**安装**:

```bash
pip install piper-tts

# 下载模型
mkdir -p models/piper
cd models/piper
wget https://github.com/rhasspy/piper/releases/download/v1.2.0/piper_zh_CN_Huayan_medium.onnx
wget https://github.com/rhasspy/piper/releases/download/v1.2.0/piper_zh_CN_Huayan_medium.onnx.json
```

### 9.3 LLM模型 - TinyLlama

**推荐配置**:

```yaml
模型: TinyLlama-1.1B-Chat.Q4_0.gguf
大小: ~700MB
内存占用: ~800MB
推理速度: 10-15 tokens/second
量化: 4-bit
```

**安装**:

```bash
# 使用llama.cpp
pip install llama-cpp-python

# 下载模型
mkdir -p models/tinyllama
cd models/tinyllama
wget https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat.Q4_0-GGUF/resolve/main/tinyllama-1.1b-chat.Q4_0.gguf
```

### 9.4 内存预算

| 组件 | 占用 | 备注 |
|------|------|------|
| Ubuntu系统 | 300MB | 基础系统 |
| Python环境 | 100MB | Python + 依赖 |
| ASR (Sherpa) | 400MB | 模型预加载 |
| TTS (Piper) | 200MB | 模型预加载 |
| LLM (TinyLlama) | 800MB | 按需加载 |
| SQLite | 50MB | 数据库文件 |
| 服务进程 | 150MB | 各服务运行 |
| **总计** | **~2GB** | 剩余 2GB 可用 |

### 9.5 模型加载策略

```python
# model_manager.py - 模型管理器
class ModelManager:
    def __init__(self):
        self.asr_model = None
        self.tts_model = None
        self.llm_model = None

    def load_asr(self):
        """按需加载ASR模型"""
        if self.asr_model is None:
            self.asr_model = sherpa_onnx.OfflineRecognizer.from_files(...)
        return self.asr_model

    def load_tts(self):
        """按需加载TTS模型"""
        if self.tts_model is None:
            self.tts_model = piper.PiperVoice.load(...)
        return self.tts_model

    def load_llm(self):
        """按需加载LLM模型（网络故障时使用）"""
        if self.llm_model is None:
            self.llm_model = llama_cpp.Llama(...)
        return self.llm_model

    def unload_llm(self):
        """释放LLM模型内存"""
        if self.llm_model:
            del self.llm_model
            self.llm_model = None
            import gc
            gc.collect()
```

---

## 10. 云端服务配置

### 10.1 Claude API配置

```yaml
# Claude API配置
claude:
  api_key: "YOUR_CLAUDE_API_KEY"
  model: "claude-sonnet-4-20250514"
  max_tokens: 1024
  temperature: 0.7

# 成本估算
使用量: 15次对话/天 × 500 tokens/次 = 7500 tokens/天
月成本: 7500 × 30 × ¥0.00002 = ¥4.5/月
```

### 10.2 天气API配置

```yaml
# 和风天气API配置
qweather:
  api_key: "YOUR_QWEATHER_API_KEY"
  location: "101280600"  # 深圳
  base_url: "https://api.qweather.com/v7"

# 免费版限制: 1000次/天，足够个人使用
```

### 10.3 配置示例

```yaml
# config.yaml - 配置文件
app:
  name: "MindNote"
  mode: "hybrid"  # local / cloud / hybrid

# 硬件配置
hardware:
  device: "rpi5"
  wakeword: "小心"

# 语音配置
audio:
  sample_rate: 16000
  channels: 1
  input_device: 0
  output_device: 1

# ASR配置
asr:
  local: true
  local_model: "sherpa-onnx-conformer-zh-small"
  cloud: true
  cloud_provider: "iflytek"
  cloud_api_key: "YOUR_IFLYTEK_KEY"

# TTS配置
tts:
  local: true
  local_model: "zh_CN_Huayan-medium"
  cloud: true
  cloud_provider: "iflytek"

# LLM配置
llm:
  local: true
  local_model: "TinyLlama-1.1B-Chat.Q4_0.gguf"
  cloud: true
  cloud_provider: "anthropic"
  cloud_api_key: "YOUR_CLAUDE_KEY"

# 天气配置
weather:
  provider: "qweather"
  api_key: "YOUR_QWEATHER_KEY"
  location: "深圳"

# 数据库配置
database:
  path: "data/mindnote.db"

# 日志配置
logging:
  level: "INFO"
  file: "logs/mindnote.log"
```

---

## 11. 延迟与性能

### 11.1 端到端延迟对比

| 场景 | 纯云端 | 纯本地 | 混合架构 |
|------|--------|--------|---------|
| 唤醒响应 | <100ms | <100ms | <100ms |
| VAD检测 | <50ms | <50ms | <50ms |
| ASR识别 | 300-500ms | 500-1000ms | **500-800ms** |
| 意图分类 | <50ms | <50ms | <50ms |
| LLM推理 | 500-1500ms | 5-15 tok/s | **800-1500ms** |
| TTS合成 | 200-400ms | 50-150ms | **50-150ms** |
| **总计** | **1.1-2.5秒** | **2-5秒** | **1.5-3秒** |

### 11.2 场景延迟详情

| 对话类型 | 混合架构延迟 | 说明 |
|----------|-------------|------|
| "现在几点了" | ~0.8s | 全本地处理 |
| "打开灯光" | ~0.5s | 全本地处理 |
| "天气怎么样" | ~1.5s | 本地ASR + 云端天气查询 |
| "我今天好累" | ~2.5s | 本地ASR + Claude云端 |
| "讲个笑话" | ~2s | 本地ASR + Claude云端 |

### 11.3 性能优化建议

```python
# 1. ASR优化: 使用onnxruntime优化
import onnxruntime as ort

options = ort.SessionOptions()
options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL
session = ort.InferenceSession("model.onnx", options)

# 2. LLM优化: 4-bit量化
llm = llama_cpp.Llama(
    model_path="model.Q4_0.gguf",
    n_gpu_layers=0,  # 树莓派5没有独立GPU
    n_threads=4,     # 使用4核CPU
    n_batch=512,     # 批处理大小
    n_ctx=2048,      # 上下文长度
)

# 3. TTS优化: 音频流式输出
async def stream_tts(text):
    """流式生成和播放TTS"""
    chunks = synthesizer.synthesize_streaming(text)
    for chunk in chunks:
        await play_audio_chunk(chunk)

# 4. 内存优化: 及时释放
def process_with_cleanup():
    try:
        result = heavy_model.inference(data)
        return result
    finally:
        # 及时释放内存
        del heavy_model
        import gc
        gc.collect()
```

### 11.4 稳定性指标

| 指标 | 目标值 | 测试方法 |
|------|--------|---------|
| 在线率 | >99% | 30天连续运行测试 |
| 语音识别率 | >95% | 100次测试 |
| 对话成功率 | >98% | 1000次对话测试 |
| 内存稳定 | <80% | 24小时监控 |
| 温度控制 | <70°C | 满载运行测试 |

---

## 12. 开发路线图

### Phase 1: 原型验证 (2-3周)

| 周次 | 任务 | 交付物 |
|------|------|--------|
| Week 1 | 系统准备、语音链路 | 录音→识别→TTS→播放 |
| | - 烧录Ubuntu 24.04 | |
| | - 配置Python环境 | |
| | - 部署Sherpa-onnx ASR | |
| | - 部署Piper TTS | |
| | - 测试端到端延迟 | |
| Week 2 | 数据服务、传感器 | 环境数据采集 |
| | - SQLite数据库搭建 | |
| | - SHT30传感器集成 | |
| | - 对话记录服务 | |
| | - 天气API集成 | |
| Week 3 | 意图分流、体验优化 | 完整Demo |
| | - 本地意图分类器 | |
| | - 对话路由器 | |
| | - 本地意图处理 | |
| | - Claude API集成 | |

### Phase 2: 功能完善 (2-3周)

| 周次 | 任务 | 交付物 |
|------|------|--------|
| Week 4 | AI人格调优 | 对话质量提升 |
| | - 优化Claude prompt | |
| | - 调整对话策略 | |
| | - 收集反馈迭代 | |
| Week 5 | 主动关怀 | 定时问候功能 |
| | - 定时任务系统 | |
| | - 问候话术设计 | |
| | - 环境感知联动 | |
| Week 6 | 情绪洞察 | 周报/月报生成 |
| | - 情绪分析服务 | |
| | - 周报生成 | |
| | - 可视化展示 | |

### Phase 3: 产品化 (2-3周)

| 周次 | 任务 | 交付物 |
|------|------|--------|
| Week 7 | 稳定性测试 | 30天无故障 |
| | - 压力测试 | |
| | - 异常恢复 | |
| | - 内存优化 | |
| Week 8 | 外壳设计 | 3D打印/亚克力外壳 |
| | - 外壳设计 | |
| | - 3D打印/激光切割 | |
| | - 组装测试 | |
| Week 9 | 文档完善 | 用户手册、API文档 |
| | - 用户手册 | |
| | - API文档 | |
| | - 部署指南 | |

---

## 13. 成本分析

### 13.1 一次性成本

| 项目 | 价格 | 备注 |
|------|------|------|
| 树莓派5 4GB | ¥0 | 已有 |
| 官方PD充电器 | ¥100 | 必须品 |
| 64GB SD卡 | ¥50 | 系统盘 |
| USB麦克风 | ¥50 | 输入设备 |
| SHT30传感器 | ¥15 | 温湿度 |
| 杜邦线 | ¥5 | 连接线 |
| 散热外壳 | ¥30 | 散热 |
| 风扇 | ¥15 | 散热 |
| 亚克力外壳 | ¥80 | 保护 |
| **总计** | **¥345** | - |

### 13.2 月度运营成本

| 服务 | 用量 | 单价 | 月成本 |
|------|------|------|--------|
| Claude API | 450K tokens/月 | ¥0.00002/token | ¥9 |
| 和风天气API | 免费 | - | ¥0 |
| **总计** | - | - | **¥9/月** |

### 13.3 对比分析

| 方案 | 硬件成本 | 月成本 | 离线能力 | 体验 |
|------|---------|--------|---------|------|
| 纯云端 | ¥200 | ¥30-40 | ❌ | ⭐⭐⭐⭐⭐ |
| 混合架构 | ¥345 | ¥9 | ✅ (基础) | ⭐⭐⭐⭐ |
| 纯本地 | ¥400 | ¥0 | ✅ (完整) | ⭐⭐⭐ |

### 13.4 成本优化建议

1. **ASR/TTS本地化** → 节省 ¥4.5/月
2. **Claude缓存** → 减少30%调用量
3. **批量采购** → 硬件成本降低20%

---

## 14. 总结

### 14.1 架构核心优势

1. **体验优先** - 延迟控制在1.5-3秒，满足实时对话需求
2. **成本可控** - 月成本¥9，远低于纯云端方案
3. **离线可用** - 基础功能在无网络时仍可使用
4. **隐私保护** - 对话数据优先本地处理
5. **技术先进** - 探索边缘AI部署，积累技术经验

### 14.2 技术创新点

1. **本地ASR部署** - Sherpa-onnx在ARM平台优化
2. **离线TTS** - Piper本地语音合成
3. **混合路由** - 智能意图分流，本地/云端协同
4. **边缘LLM探索** - TinyLlama在树莓派上的部署验证

### 14.3 下一步行动

1. **立即执行**:
   - [ ] 采购硬件配件
   - [ ] 烧录Ubuntu系统
   - [ ] 部署Sherpa-onnx ASR

2. **短期目标**:
   - [ ] 跑通完整语音链路
   - [ ] 集成Claude API
   - [ ] 实现意图分流

3. **中期目标**:
   - [ ] 优化对话体验
   - [ ] 添加主动关怀
   - [ ] 开发情绪洞察

### 14.4 风险与应对

| 风险 | 等级 | 应对措施 |
|------|------|----------|
| 本地ASR准确率不足 | 中 | 保留云端备用方案 |
| LLM推理过热 | 中 | 配备散热，优化加载策略 |
| Claude API成本超预期 | 低 | 优化prompt，减少token |
| 硬件兼容性 | 低 | 充分测试，使用成熟方案 |

---

**文档版本**: v2.0
**更新日期**: 2026年1月12日
**作者**: 个人项目
