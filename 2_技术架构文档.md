# MindNote 情绪陪伴 AI - 技术架构文档 v2

## 1. 架构设计理念

### 1.1 核心原则

```
语音对话为核心，本地优先 + 云端增强

用户 ←→ 语音交互 ←→ 对话引擎 ←→ 数据服务
                         ↓
                    设备自主运行
                    （不依赖外部调用）
```

### 1.2 与 v1 架构的区别

| 维度 | v1 架构 (MCP 驱动) | v2 架构 (语音驱动) |
|------|-------------------|-------------------|
| 核心 | MCP 工具被外部调用 | 语音对话主动交互 |
| 设备角色 | 被动响应 | 主动运行 |
| 依赖 | 需要外部 AI 助手 | 独立完成交互 |
| MCP 定位 | 核心功能 | 可选开放接口 |

## 2. 系统架构总览

```
┌─────────────────────────────────────────────────────────────────────┐
│                        MindNote 系统架构                             │
├─────────────────────────────────────────────────────────────────────┤
│                                                                     │
│  ┌───────────────────────────────────────────────────────────────┐ │
│  │                    Layer 1: 语音交互层                         │ │
│  │  ┌─────────┐  ┌─────────┐  ┌─────────┐  ┌─────────┐          │ │
│  │  │ 唤醒词  │→│  VAD   │→│  ASR   │  │  TTS   │          │ │
│  │  │检测    │  │语音检测 │  │语音识别 │  │语音合成 │          │ │
│  │  └─────────┘  └─────────┘  └─────────┘  └─────────┘          │ │
│  └───────────────────────────────────────────────────────────────┘ │
│                              ↓ 文本                                 │
│  ┌───────────────────────────────────────────────────────────────┐ │
│  │                    Layer 2: 对话引擎层                         │ │
│  │  ┌─────────────┐      ┌─────────────┐      ┌─────────────┐   │ │
│  │  │ 本地意图识别 │ ──→ │  对话路由器  │ ──→ │ 云端 LLM    │   │ │
│  │  │ (设备控制)  │      │            │      │ (情感对话)  │   │ │
│  │  └─────────────┘      └─────────────┘      └─────────────┘   │ │
│  └───────────────────────────────────────────────────────────────┘ │
│                              ↓                                      │
│  ┌───────────────────────────────────────────────────────────────┐ │
│  │                    Layer 3: 数据服务层                         │ │
│  │  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐           │ │
│  │  │ 对话记录    │  │ 情绪分析    │  │ 环境数据    │           │ │
│  │  │ 服务       │  │ 服务       │  │ 服务       │           │ │
│  │  └─────────────┘  └─────────────┘  └─────────────┘           │ │
│  └───────────────────────────────────────────────────────────────┘ │
│                              ↓                                      │
│  ┌───────────────────────────────────────────────────────────────┐ │
│  │                    Layer 4: 设备控制层                         │ │
│  │  ┌────────┐  ┌────────┐  ┌────────┐  ┌────────┐              │ │
│  │  │ 音量   │  │ 灯光   │  │ 屏幕   │  │ 传感器 │              │ │
│  │  └────────┘  └────────┘  └────────┘  └────────┘              │ │
│  └───────────────────────────────────────────────────────────────┘ │
│                              ↓                                      │
│  ┌───────────────────────────────────────────────────────────────┐ │
│  │                Layer 5: 开放接口层 (可选/未来)                  │ │
│  │  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐           │ │
│  │  │ REST API   │  │ MCP Server │  │ App 接口    │           │ │
│  │  │ (局域网)   │  │ (AI助手)   │  │ (移动端)   │           │ │
│  │  └─────────────┘  └─────────────┘  └─────────────┘           │ │
│  └───────────────────────────────────────────────────────────────┘ │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

## 3. Layer 1: 语音交互层

### 3.1 语音处理流程

```
用户说话
    │
    ▼
┌─────────────────┐
│  唤醒词检测      │ ← Porcupine，持续低功耗监听
│  "小心"         │    误唤醒率 <1次/天
└─────────────────┘
    │ 唤醒成功，灯光亮起
    ▼
┌─────────────────┐
│  VAD 语音检测    │ ← 检测说话开始/结束
│                 │    支持打断
└─────────────────┘
    │ 录音完成
    ▼
┌─────────────────┐
│  ASR 语音识别    │ ← 云端讯飞 (主) / 本地 Sherpa (备)
│                 │    准确率 >95%
└─────────────────┘
    │ 文本结果
    ▼
  对话引擎层
```

### 3.2 技术选型

| 模块 | 方案 | 延迟 | 成本 | 备注 |
|------|------|------|------|------|
| 唤醒词 | Porcupine | <100ms | 免费(内置词) | 自定义词需付费 |
| VAD | WebRTC VAD | <50ms | 免费 | 本地运行 |
| ASR | 讯飞云端 | 300-500ms | ¥0.005/次 | 准确率高 |
| ASR备用 | Sherpa-onnx | 200-500ms | 免费 | 离线可用 |
| TTS | 讯飞云端 | 200-400ms | ¥0.002/字 | 音质好 |
| TTS备用 | Piper | 100-300ms | 免费 | 简单回复用 |

## 4. Layer 2: 对话引擎层

### 4.1 对话路由设计

```
用户输入文本
      │
      ▼
┌──────────────────┐
│  本地意图识别     │ ← TFLite 模型，<50ms
│  (20+ 意图分类)   │
└──────────────────┘
      │
      ├─── 设备控制意图 ───→ 本地处理器 → 本地 TTS
      │    "音量大一点"        执行控制     "好的"
      │    响应时间: <500ms
      │
      ├─── 快速查询意图 ───→ 本地处理器 → 本地 TTS
      │    "现在几点"          查询数据     "下午3点"
      │    响应时间: <500ms
      │
      └─── 情感/复杂意图 ──→ 云端 LLM → 云端 TTS
           "我今天好累"        深度对话    温暖回复
           响应时间: 1-3s
```

### 4.2 本地意图分类

```python
# 本地处理的意图（约 15 个）- 快速响应
LOCAL_INTENTS = {
    # 设备控制
    "volume_up": ["大声点", "音量调高", "听不清"],
    "volume_down": ["小声点", "音量调低", "太吵了"],
    "volume_set": ["音量调到50", "音量80"],
    "light_on": ["开灯", "打开灯光"],
    "light_off": ["关灯", "把灯关了"],
    "light_color": ["蓝色灯光", "暖光", "换个颜色"],
    
    # 快速查询
    "query_time": ["几点了", "现在时间"],
    "query_date": ["今天几号", "星期几"],
    "query_weather": ["天气怎么样", "会下雨吗"],
    "query_environment": ["房间温度", "湿度多少"],
    
    # 系统控制
    "stop": ["停", "闭嘴", "别说了"],
    "repeat": ["再说一遍", "没听清"],
    "cancel": ["取消", "算了"],
}

# 路由到云端的意图 - 需要深度理解
CLOUD_INTENTS = {
    "emotion_talk": ["我好累", "心情不好", "很开心", "有点焦虑"],
    "casual_chat": ["聊聊天", "无聊", "陪我说话"],
    "ask_advice": ["怎么办", "给我建议"],
    "share_story": ["告诉你一件事", "今天发生了"],
    "query_emotion": ["我最近情绪怎么样", "上周聊了什么"],
}
```

### 4.3 云端 LLM 对话

```python
# AI 人格 System Prompt
SYSTEM_PROMPT = """
你是小心，一个温暖、善解人意的情绪陪伴伙伴。

## 你的性格
- 温暖、耐心、善于倾听
- 像一个贴心的朋友，不是冷冰冰的助手
- 偶尔俏皮，但不轻浮
- 真诚关心用户，不敷衍

## 对话原则
- 先倾听和共情，再给建议
- 不说教，不评判
- 用简短、自然的语言回复
- 记住用户说过的事情，建立长期关系

## 边界
- 不提供医疗/心理诊断建议
- 严重情况建议寻求专业帮助
- 不讨论政治、宗教等敏感话题

## 当前上下文
用户名: {user_name}
当前时间: {current_time}
环境: 室内{temperature}°C，{weather}
最近情绪: {recent_mood}
"""

# 对话历史管理
class ConversationManager:
    def __init__(self):
        self.history = []  # 最近 10 轮对话
        self.user_profile = {}  # 用户画像
    
    def add_message(self, role, content):
        self.history.append({"role": role, "content": content})
        if len(self.history) > 20:
            self.history = self.history[-20:]
    
    def get_context(self):
        return self.history
```

## 5. Layer 3: 数据服务层

### 5.1 服务模块设计

数据服务是内部模块，不对外暴露，供对话引擎调用。

```
┌─────────────────────────────────────────────────────────────┐
│                      数据服务层                              │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  ┌─────────────────┐  ┌─────────────────┐                  │
│  │ ConversationDB  │  │ EmotionService  │                  │
│  │ 对话记录服务     │  │ 情绪分析服务     │                  │
│  │                 │  │                 │                  │
│  │ • 保存对话历史   │  │ • 从对话提取情绪 │                  │
│  │ • 查询历史对话   │  │ • 记录情绪数据   │                  │
│  │ • 生成对话摘要   │  │ • 生成情绪报告   │                  │
│  └─────────────────┘  └─────────────────┘                  │
│                                                             │
│  ┌─────────────────┐  ┌─────────────────┐                  │
│  │ EnvironmentSvc  │  │ InsightService  │                  │
│  │ 环境数据服务     │  │ 洞察生成服务     │                  │
│  │                 │  │                 │                  │
│  │ • 读取传感器    │  │ • 分析情绪趋势   │                  │
│  │ • 获取天气数据  │  │ • 环境关联分析   │                  │
│  │ • 记录环境历史  │  │ • 生成改善建议   │                  │
│  └─────────────────┘  └─────────────────┘                  │
│                                                             │
│  ┌─────────────────────────────────────────────────────┐   │
│  │                   SQLite 数据库                      │   │
│  │  conversations | emotions | environment | insights  │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

### 5.2 数据模型

```sql
-- 对话记录
CREATE TABLE conversations (
    id INTEGER PRIMARY KEY,
    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
    user_input TEXT,
    ai_response TEXT,
    intent TEXT,
    emotion_detected TEXT,
    duration_seconds INTEGER
);

-- 情绪记录
CREATE TABLE emotions (
    id INTEGER PRIMARY KEY,
    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
    mood_score INTEGER,  -- 1-10
    mood_tags TEXT,      -- JSON array
    source TEXT,         -- 'conversation' | 'manual'
    environment_id INTEGER
);

-- 环境数据
CREATE TABLE environment (
    id INTEGER PRIMARY KEY,
    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
    temperature REAL,
    humidity REAL,
    light_level INTEGER,
    weather TEXT,
    weather_temp REAL
);
```

## 6. Layer 4: 设备控制层

### 6.1 硬件控制接口

```python
class DeviceController:
    """设备控制器 - 本地执行，无需云端"""
    
    def __init__(self):
        self.volume = 70
        self.brightness = 80
        self.light_on = True
        self.light_color = (255, 200, 150)  # 暖白
    
    # 音量控制
    def set_volume(self, value: int):
        self.volume = max(0, min(100, value))
        # 调用系统音量 API
    
    def volume_up(self, delta=20):
        self.set_volume(self.volume + delta)
        return "好的"
    
    def volume_down(self, delta=20):
        self.set_volume(self.volume - delta)
        return "好的，小声一点"
    
    # 灯光控制
    def set_light(self, on: bool, color: tuple = None):
        self.light_on = on
        if color:
            self.light_color = color
        # 调用 LED 控制 API
    
    def set_light_color(self, color_name: str):
        colors = {
            "红": (255, 0, 0), "蓝": (0, 0, 255),
            "绿": (0, 255, 0), "暖": (255, 200, 150),
            "白": (255, 255, 255)
        }
        self.set_light(True, colors.get(color_name, (255, 255, 255)))
        return f"好的，已切换到{color_name}色"
    
    # 灯光状态反馈
    def show_listening(self):
        """聆听状态 - 蓝色渐亮"""
        pass
    
    def show_thinking(self):
        """思考状态 - 蓝色流动"""
        pass
    
    def show_speaking(self):
        """说话状态 - 随语音律动"""
        pass
    
    def show_idle(self):
        """待机状态 - 柔和呼吸灯"""
        pass
```

## 7. Layer 5: 开放接口层 (可选/未来)

### 7.1 定位说明

开放接口是可选功能，优先级低于核心语音交互。用于：
- App 查看数据和设置
- 外部 AI 助手（如 Claude Desktop）查询设备状态
- 智能家居集成

### 7.2 REST API (Phase 2)

```yaml
# 供 App 和局域网设备调用
endpoints:
  # 设备状态
  GET  /api/status              # 获取设备状态
  POST /api/device/volume       # 音量控制
  POST /api/device/light        # 灯光控制
  
  # 数据查询
  GET  /api/emotions            # 情绪记录
  GET  /api/conversations       # 对话历史
  GET  /api/insights            # 情绪洞察
  
  # 设置
  GET  /api/settings            # 获取设置
  PUT  /api/settings            # 更新设置
```

### 7.3 MCP Server (Phase 3+)

MCP 作为开放接口，让外部 AI 助手可以查询设备：

```typescript
// MCP 工具定义 - 只读查询为主
tools:
  - name: get_user_mood
    description: "获取用户最近的情绪状态"
    
  - name: get_mood_history
    description: "获取情绪历史趋势"
    
  - name: get_environment
    description: "获取当前环境数据"
    
  - name: send_message
    description: "让设备对用户说一句话"
```

**注意**：MCP 不是核心功能，设备可以完全不依赖 MCP 独立运行。

## 8. 硬件方案

### 8.1 推荐配置：树莓派 Zero 2W

```
┌─────────────────────────────────────────────────────────────┐
│                    MindNote 硬件架构                         │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│   ┌─────────────────────────────────────────────────────┐  │
│   │              树莓派 Zero 2W (主控)                   │  │
│   │  • 1GHz 四核 ARM Cortex-A53                        │  │
│   │  • 512MB RAM                                        │  │
│   │  • WiFi + Bluetooth                                 │  │
│   │  • 运行 Linux + Python                              │  │
│   └─────────────────────────────────────────────────────┘  │
│          │           │           │           │              │
│          ▼           ▼           ▼           ▼              │
│   ┌──────────┐ ┌──────────┐ ┌──────────┐ ┌──────────┐     │
│   │ 麦克风   │ │ 扬声器   │ │ 小屏幕   │ │ RGB LED  │     │
│   │ INMP441  │ │ MAX98357 │ │ 1.3" LCD │ │ WS2812   │     │
│   └──────────┘ └──────────┘ └──────────┘ └──────────┘     │
│                                                             │
│   ┌──────────────────────────────────────────────────┐     │
│   │  传感器: SHT30 温湿度 + BH1750 光照 + 触摸按键    │     │
│   └──────────────────────────────────────────────────┘     │
│                                                             │
└─────────────────────────────────────────────────────────────┘

预估成本: ¥300-350
```

### 8.2 软件目录结构

```
/home/pi/mindnote/
├── main.py                 # 主程序入口
├── config.yaml             # 配置文件
│
├── audio/                  # 语音交互层
│   ├── wakeword.py        # 唤醒词检测
│   ├── vad.py             # 语音活动检测
│   ├── asr.py             # 语音识别
│   └── tts.py             # 语音合成
│
├── dialog/                 # 对话引擎层
│   ├── intent_classifier.py   # 本地意图分类
│   ├── local_handler.py       # 本地意图处理
│   ├── cloud_handler.py       # 云端 LLM 对话
│   └── router.py              # 对话路由
│
├── services/               # 数据服务层
│   ├── conversation_db.py # 对话记录
│   ├── emotion_service.py # 情绪分析
│   ├── environment_svc.py # 环境数据
│   └── insight_service.py # 洞察生成
│
├── device/                 # 设备控制层
│   ├── controller.py      # 设备控制器
│   ├── led.py             # LED 灯光
│   ├── display.py         # 屏幕显示
│   └── sensors.py         # 传感器读取
│
├── api/                    # 开放接口层 (可选)
│   ├── rest_api.py        # REST API
│   └── mcp_server.py      # MCP Server
│
└── data/
    └── mindnote.db        # SQLite 数据库
```

## 9. 主程序流程

```python
# main.py - 主程序入口
import asyncio
from audio import WakewordDetector, VAD, ASR, TTS
from dialog import IntentClassifier, LocalHandler, CloudHandler, Router
from device import DeviceController
from services import ConversationDB, EmotionService

class MindNote:
    def __init__(self):
        # 初始化各层
        self.wakeword = WakewordDetector("小心")
        self.vad = VAD()
        self.asr = ASR()
        self.tts = TTS()
        
        self.intent_classifier = IntentClassifier()
        self.local_handler = LocalHandler()
        self.cloud_handler = CloudHandler()
        self.router = Router()
        
        self.device = DeviceController()
        self.conversation_db = ConversationDB()
        self.emotion_service = EmotionService()
    
    async def run(self):
        """主循环"""
        print("MindNote 启动，等待唤醒...")
        self.device.show_idle()
        
        while True:
            # 1. 等待唤醒
            await self.wakeword.wait_for_wakeword()
            self.device.show_listening()
            self.tts.speak("我在")
            
            # 2. 连续对话循环
            while True:
                # 录音
                audio = await self.vad.record_until_silence()
                if audio is None:  # 超时无输入
                    self.tts.speak("有事再叫我")
                    break
                
                # 语音识别
                self.device.show_thinking()
                text = await self.asr.recognize(audio)
                
                # 意图识别 & 路由
                intent = self.intent_classifier.classify(text)
                
                if self.router.is_local_intent(intent):
                    # 本地处理
                    response = self.local_handler.handle(intent, text)
                    self.tts.speak_local(response)  # 本地 TTS
                else:
                    # 云端处理
                    response = await self.cloud_handler.chat(text)
                    self.tts.speak_cloud(response)  # 云端 TTS
                
                # 记录对话
                self.conversation_db.save(text, response, intent)
                
                # 情绪分析
                emotion = self.emotion_service.analyze(text, response)
                if emotion:
                    self.emotion_service.record(emotion)
                
                self.device.show_idle()

if __name__ == "__main__":
    app = MindNote()
    asyncio.run(app.run())
```

## 10. 开发路线图

### Phase 1: 语音链路验证 (2周)
- [ ] 搭建树莓派开发环境
- [ ] 集成讯飞 ASR/TTS
- [ ] 实现 "说话 → 识别 → 回复 → 播放" 完整链路
- [ ] 验证端到端延迟

### Phase 2: 对话引擎开发 (3周)
- [ ] 训练本地意图分类模型
- [ ] 实现设备控制本地处理
- [ ] 集成云端 LLM (Claude/GPT)
- [ ] 设计 AI 人格 Prompt
- [ ] 实现对话路由

### Phase 3: 数据服务开发 (2周)
- [ ] 实现对话记录服务
- [ ] 实现情绪分析服务
- [ ] 实现环境数据服务
- [ ] 实现洞察生成服务

### Phase 4: 硬件集成 (2周)
- [ ] 集成唤醒词检测
- [ ] 集成 LED 灯光反馈
- [ ] 集成屏幕显示
- [ ] 集成传感器

### Phase 5: 优化和测试 (2周)
- [ ] 性能优化
- [ ] AI 人格调优
- [ ] 稳定性测试
- [ ] 用户测试

### Phase 6: 开放接口 (可选，2周)
- [ ] REST API 开发
- [ ] 简易 App 开发
- [ ] MCP Server 开发

**总计: 11-13 周**

## 11. 响应时间目标

| 场景 | 目标 | 实现方式 |
|------|------|----------|
| 唤醒响应 | <500ms | 本地唤醒词检测 |
| 设备控制 | <500ms | 本地意图 + 本地 TTS |
| 时间/天气查询 | <800ms | 本地意图 + 缓存数据 |
| 情感对话 | <2s | 云端 ASR + 云端 LLM + 云端 TTS |
| 复杂问答 | <3s | 云端全链路 |

## 12. 成本估算

### 硬件成本 (一次性)
- 树莓派 Zero 2W: ¥150
- 音频模块: ¥50
- 显示+灯光: ¥40
- 传感器: ¥15
- 外壳+其他: ¥50
- **总计: ¥300-350**

### 云服务成本 (每月/每用户)
- ASR: ¥0.005/次 × 30次/天 × 30天 = ¥4.5
- TTS: ¥0.002/字 × 30字 × 15次/天 × 30天 = ¥27
- LLM: ¥0.01/次 × 15次/天 × 30天 = ¥4.5
- **总计: ¥30-40/月**

### 成本优化策略
- 设备控制用本地 TTS → 减少 50% TTS 调用
- 缓存常见回复 → 减少 LLM 调用
- 批量采购云服务 → 降低单价

## 13. 总结

### 架构核心变化
1. **语音对话为核心** - 设备主动运行，不依赖外部调用
2. **本地+云端混合** - 设备控制本地处理，情感对话走云端
3. **MCP 降级为可选** - 作为开放接口，优先级放到 Phase 6

### 关键成功因素
1. 语音链路延迟控制在 2 秒内
2. 本地意图识别准确率 >90%
3. AI 人格设计"有温度"
4. 设备控制响应 <500ms
