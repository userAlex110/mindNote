# MindNote 情绪陪伴 AI - 产品需求文档 (PRD)

## 1. 产品概述

### 1.1 产品愿景
打造一款**有温度、懂你的情绪陪伴 AI 硬件**，像一个贴心的朋友，随时倾听、理解、陪伴你。

### 1.2 产品定位
- **产品形态**: 独立 AI 硬件产品（类似华为憨憨）
- **核心能力**: 语音交互 + 情绪陪伴 + 环境感知 + 智能洞察
- **目标用户**: 需要情绪陪伴、渴望被理解的都市人群
- **交互方式**: 主要通过**语音对话**，未来支持 App

### 1.3 核心价值
- **情绪陪伴**: 随时倾听用户心声，提供温暖的情感支持（核心！）
- **主动关怀**: 感知环境和时间，在合适时机主动问候
- **智能洞察**: 基于长期陪伴数据，提供个性化的情绪建议
- **环境感知**: 监测环境数据，理解情绪与环境的关联
- **开放能力**: 未来可被云端 AI 助手调用，扩展更多场景

### 1.4 与华为憨憨的差异化
| 维度 | 华为憨憨 | MindNote |
|------|----------|----------|
| 定位 | 全能情感机器人 | 专注情绪陪伴 |
| 形态 | 可移动机器人 | 桌面摆件 |
| 交互 | 语音+表情+动作 | 语音+灯光+App |
| 特色 | 生态整合 | 情绪数据洞察 |
| 价格 | 高端 | 亲民 |

## 2. 目标用户

### 2.1 主要用户群体
- **独居青年**: 一个人生活，需要陪伴和倾诉对象
- **高压白领**: 工作压力大，需要情绪出口和支持
- **学生群体**: 学业压力、社交焦虑，需要理解和鼓励
- **情绪敏感者**: 容易情绪波动，需要稳定的情感支持

### 2.2 用户痛点
- **孤独感**: 想找人聊聊但不想麻烦朋友
- **情绪压抑**: 有些话不知道跟谁说
- **缺乏理解**: 觉得没人真正懂自己
- **情绪管理**: 不知道如何调节自己的情绪
- **记录困难**: 想记录心情但懒得打字

### 2.3 用户场景
- 🌙 **深夜emo**: "今天好累，想找人聊聊"
- 😤 **工作受挫**: "被老板骂了，好委屈"
- 🎉 **开心分享**: "今天发生了一件好事！"
- 😔 **日常倾诉**: "最近总是睡不好..."
- 🤔 **自我反思**: "我最近情绪怎么样？"

## 3. 核心功能需求

### 3.1 语音对话交互（核心功能）
**功能描述**: 用户通过语音与 AI 进行自然对话，获得情绪陪伴

**交互方式**:
- **唤醒词**: "小心"/"Hey Mind" 唤醒设备
- **按键唤醒**: 轻触设备顶部开始对话
- **连续对话**: 支持多轮对话，无需重复唤醒

**对话能力**:
- **倾听理解**: 理解用户的情绪表达和倾诉内容
- **共情回应**: 用温暖、理解的语气回应
- **适度引导**: 在合适时机引导用户表达更多
- **情绪支持**: 提供鼓励、安慰、建议
- **记忆能力**: 记住用户说过的事情，建立长期关系

**语音技术栈**:
- **ASR (语音识别)**: 讯飞/阿里云/本地 Whisper
- **TTS (语音合成)**: 选择温暖、有亲和力的音色
- **端侧 AI**: 简单意图识别（本地）
- **云端 AI**: 复杂对话理解（调用大模型 API）

### 3.2 情绪陪伴 AI
**功能描述**: 设备内置的 AI 人格，提供持续的情绪陪伴

**AI 人格设定**:
- **性格**: 温暖、耐心、善解人意、偶尔俏皮
- **角色**: 像一个贴心的朋友，不是冷冰冰的助手
- **边界**: 不提供医疗建议，严重情况建议寻求专业帮助

**陪伴场景**:
| 场景 | AI 行为 |
|------|---------|
| 用户倾诉烦恼 | 倾听、共情、适度建议 |
| 用户分享开心 | 一起开心、真诚祝贺 |
| 用户情绪低落 | 陪伴、安慰、不强行开导 |
| 用户沉默 | 安静陪伴，不打扰 |
| 深夜聊天 | 关心睡眠，温柔提醒 |

**主动关怀**:
- 早晨问候："早上好，昨晚睡得怎么样？"
- 下班时间："辛苦了，今天工作顺利吗？"
- 检测到长时间沉默："在忙吗？有空的话可以聊聊"
- 特殊日子："今天是周五，周末有什么计划？"

### 3.3 环境感知
**功能描述**: 感知环境变化，为陪伴提供上下文

**感知能力**:
- 温度监测：感知冷暖变化
- 湿度监测：感知干燥/潮湿
- 环境光监测：感知白天/夜晚
- 天气数据：通过 API 获取

**环境融入对话**:
- "今天好热啊，记得多喝水"
- "外面在下雨，适合待在家里"
- "这么晚了还没睡？"

### 3.4 情绪记录与洞察
**功能描述**: 自动记录对话中的情绪数据，生成洞察

**自动记录**:
- 从对话中提取情绪状态（AI 分析）
- 记录对话时间、时长、主题
- 关联环境数据

**洞察生成**:
- **周报**: "这周你聊了5次，整体情绪比上周好"
- **趋势**: "最近工作压力好像有点大"
- **建议**: "周末可以出去走走，放松一下"

**用户可查询**:
- "我最近情绪怎么样？"
- "上周我们聊了什么？"
- "我什么时候最开心？"

### 3.5 灯光反馈
**功能描述**: 通过灯光表达设备状态和情绪

**灯光语言**:
| 状态 | 灯光效果 |
|------|----------|
| 待机 | 柔和呼吸灯（暖白） |
| 聆听中 | 蓝色渐亮 |
| 思考中 | 蓝色流动 |
| 说话中 | 随语音律动 |
| 开心 | 暖黄色 |
| 安慰 | 柔和橙色 |
| 晚安 | 渐暗熄灭 |

### 3.6 开放接口（未来）
**功能描述**: 允许云端 AI 助手调用设备能力

**开放能力**:
- 查询用户情绪状态
- 查询历史对话摘要
- 触发设备说话
- 获取环境数据

**接口形式**:
- **本地 API**: REST API 供局域网内调用
- **MCP 协议**: 供 Claude Desktop 等 AI 助手调用
- **云端 API**: 未来支持远程调用

**隐私保护**:
- 用户授权后才能被调用
- 敏感对话内容不对外暴露
- 只提供摘要和统计数据

## 4. 用户体验流程

### 4.1 开箱体验
1. 取出设备，插上电源
2. 设备亮起欢迎灯光，语音引导配网
3. 手机扫码，连接 WiFi
4. AI 自我介绍："你好，我是小心，很高兴认识你！"
5. 简单对话，了解用户（可跳过）

### 4.2 日常使用
```
用户: "小心"
设备: (灯光亮起) "我在"
用户: "今天好累啊"
设备: "辛苦了，想聊聊发生什么了吗？"
用户: "工作上遇到了一些问题..."
设备: (倾听、共情、回应)
...
用户: "谢谢你听我说这些"
设备: "随时都可以找我聊，早点休息"
```

### 4.3 主动关怀
```
(早上 8:00)
设备: (柔和灯光) "早上好，新的一天开始了"

(晚上 11:30，检测到用户还在)
设备: "这么晚了，要不要早点休息？"
```

### 4.4 查看数据（App）
1. 打开 MindNote App
2. 查看情绪趋势图表
3. 回顾对话摘要
4. 获取周/月情绪报告
5. 调整 AI 设置（音量、主动关怀频率等）

## 5. 非功能需求

### 5.1 性能需求
- **语音响应延迟**: <2秒（从说完话到开始回复）
- **唤醒响应**: <500ms
- **本地意图识别**: <200ms
- **云端 AI 响应**: <3秒（取决于网络）
- **设备启动时间**: <10秒

### 5.2 可靠性需求
- **设备在线率**: >99%
- **语音识别准确率**: >95%（安静环境）
- **断网处理**: 本地基础对话能力，联网后同步
- **数据保存**: 本地存储 + 云端备份

### 5.3 易用性需求
- **零配置**: 插电即用，语音引导配网
- **自然交互**: 像和朋友聊天一样自然
- **无需 App**: 核心功能不依赖手机
- **灯光直观**: 一眼看懂设备状态

### 5.4 隐私安全
- **本地优先**: 对话数据优先存储在本地
- **端到端加密**: 云端传输加密
- **用户可控**: 可随时删除所有数据
- **透明告知**: 明确告知数据用途

## 6. 技术架构概览

### 6.1 硬件架构
```
┌─────────────────────────────────────┐
│           MindNote 设备             │
├─────────────────────────────────────┤
│  🎤 麦克风阵列 (语音输入)            │
│  🔊 扬声器 (语音输出)                │
│  💡 RGB LED (灯光反馈)              │
│  🌡️ 温湿度传感器                    │
│  💡 光线传感器                      │
│  🔘 触摸按键                        │
├─────────────────────────────────────┤
│  ESP32-S3 (主控，支持语音前端处理)   │
│  或 树莓派 Zero 2W (更强算力)        │
├─────────────────────────────────────┤
│  WiFi 连接                          │
│  本地存储 (SD卡/Flash)              │
└─────────────────────────────────────┘
```

### 6.2 软件架构
```
┌─────────────────────────────────────────────────────┐
│                    用户交互层                        │
│  语音对话 ←→ [ASR] ←→ [AI对话] ←→ [TTS] ←→ 语音输出  │
└─────────────────────────────────────────────────────┘
                          ↓
┌─────────────────────────────────────────────────────┐
│                    AI 服务层                         │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐  │
│  │ 端侧轻量AI  │  │ 云端大模型  │  │ 情绪分析    │  │
│  │ (意图识别)  │  │ (深度对话)  │  │ (洞察生成)  │  │
│  └─────────────┘  └─────────────┘  └─────────────┘  │
└─────────────────────────────────────────────────────┘
                          ↓
┌─────────────────────────────────────────────────────┐
│                    数据层                            │
│  对话记录 │ 情绪数据 │ 环境数据 │ 用户画像          │
└─────────────────────────────────────────────────────┘
                          ↓
┌─────────────────────────────────────────────────────┐
│                    开放接口层                        │
│  本地 REST API │ MCP Server │ 云端 API (未来)       │
└─────────────────────────────────────────────────────┘
```

### 6.3 关键技术选型
| 模块 | 方案 A (低成本) | 方案 B (高性能) |
|------|----------------|----------------|
| 主控 | ESP32-S3 | 树莓派 Zero 2W |
| ASR | 云端 (讯飞/阿里) | 本地 Whisper |
| TTS | 云端 (讯飞/阿里) | 本地 VITS |
| AI 对话 | 云端大模型 API | 云端 + 本地缓存 |
| 存储 | Flash + 云端 | SD卡 + 云端 |

## 7. 商业模式

### 7.1 MVP阶段 (个人作品)
- 自己使用 + 送给朋友
- 收集真实反馈
- 验证产品价值

### 7.2 商业化阶段
- **硬件销售**: 299-499 元/台
- **AI 服务订阅**: 9.9-19.9 元/月（云端 AI 调用）
- **免费基础版**: 本地基础对话免费，高级功能付费

## 8. 成功指标

### 8.1 产品指标
- **对话频率**: 用户每周主动对话 >3 次
- **对话时长**: 平均每次对话 >2 分钟
- **用户留存**: 30天留存 >50%
- **NPS 评分**: >40

### 8.2 情感指标
- 用户反馈"感到被理解"
- 用户反馈"情绪有改善"
- 用户愿意推荐给朋友

### 8.3 技术指标
- 语音识别准确率: >95%
- 对话响应延迟: <2秒
- 设备稳定性: 连续工作30天无故障

## 9. 风险与应对

### 9.1 技术风险
| 风险 | 应对策略 |
|------|----------|
| 语音识别不准 | 使用成熟云服务，优化麦克风阵列 |
| AI 响应慢 | 本地缓存常见回复，优化 prompt |
| 硬件成本高 | 先用开发板验证，再定制 PCB |
| 断网不可用 | 本地基础对话能力兜底 |

### 9.2 产品风险
| 风险 | 应对策略 |
|------|----------|
| AI 回复不够"懂人" | 精心设计 prompt，持续优化 |
| 用户觉得"没用" | 强化情感价值，弱化工具属性 |
| 隐私担忧 | 本地优先，透明告知，用户可控 |
| 与憨憨等竞品竞争 | 差异化定位，专注情绪陪伴 |

### 9.3 伦理风险
| 风险 | 应对策略 |
|------|----------|
| 用户过度依赖 | 适时引导现实社交 |
| 严重心理问题 | 识别并建议寻求专业帮助 |
| 数据滥用 | 严格隐私政策，不卖数据 |

## 10. 开发路线图

### Phase 1: 原型验证 (1-2个月)
- [ ] 硬件选型：ESP32-S3 或树莓派
- [ ] 语音链路打通：ASR → AI → TTS
- [ ] 基础对话能力验证
- [ ] 简单灯光反馈

### Phase 2: MVP (2-3个月)
- [ ] 完整语音交互体验
- [ ] AI 人格调优
- [ ] 情绪记录功能
- [ ] 基础 App（查看数据）

### Phase 3: 完善 (3-4个月)
- [ ] 主动关怀功能
- [ ] 情绪洞察报告
- [ ] 开放接口（MCP/API）
- [ ] 外观设计定型

### Phase 4: 量产准备
- [ ] 定制 PCB
- [ ] 外壳开模
- [ ] 小批量试产
- [ ] 用户测试

## 11. 下一步行动

### 立即要做
1. **硬件选型决策**: ESP32-S3 vs 树莓派，评估算力和成本
2. **语音方案验证**: 测试讯飞/阿里云 ASR+TTS 效果
3. **AI 对话原型**: 用 Claude/GPT API 验证对话体验

### 本周目标
- 搭建一个最简单的语音对话 demo
- 验证"说话 → AI回复 → 播放"的完整链路
- 体验是否足够"有温度"

### 需要思考的问题
- [ ] AI 人格具体怎么设定？叫什么名字？
- [ ] 唤醒词用什么？怎么实现？
- [ ] 云端 AI 成本怎么控制？
- [ ] 外观设计什么风格？
